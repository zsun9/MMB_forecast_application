{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifiy raw variables you wish to download from ALFRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "      # 'GDPC1', 'GDPCTPI', 'PCEC', 'FPI', 'PRFI', 'PNFI', 'PCND', 'PCESV', 'PCDG', 'PCNDGC96', 'PCESVC96', 'PCDGCC96', 'COMPNFB', 'PRS85006023', 'BOGZ1FL144104005Q', 'HMLBSHNO', # quarterly 1\n",
    "#      'A007RD3Q086SBEA', 'A006RD3Q086SBEA', 'GPDIC1', 'GPDI', 'HOANBS', 'NETEXP', 'NETEXC', 'TOTLQ', 'PNFIC1', 'PRFIC1', 'IPDNBS', 'DNDGRD3Q086SBEA', 'DSERRD3Q086SBEA', 'DDURRD3Q086SBEA', 'GCEC1', 'COMPRNFB'   # quarterly 2\n",
    "#          'A957RC1Q027SBEA' , 'A787RC1Q027SBEA',  'AD08RC1Q027SBEA',  'A918RC1Q027SBEA' # quarterly\n",
    "        'RENTIN','CPROFIT','W255RC1Q027SBEA','PROPINC','A074RC1Q027SBEA','W071RC1Q027SBEA','WASCUR','PROPINC','COE','W780RC1Q027SBEA'  #quarterly\n",
    "#      'PCEND', 'CES2000000007', 'AHETPI', 'CE16OV', 'CNP16OV', 'AWHNONAG', 'UNRATE', 'CPIAUCSL', # monthly 1\n",
    "#      'PCEC96', 'PCE', 'PCENDC96', 'PCEDG', 'PCEDGC96', # monthly 2\n",
    "#      'PCES', 'PCESC96', 'CLF16OV', 'BAA', 'TB3MS', 'PAYEMS', 'USCONS', 'AWHMAN', 'AWHAECON', 'CES2000000008', 'CPILFESL', 'EMRATIO', 'CIVPART', 'JTSJOL',  # monthly 3\n",
    "#      'DFF', 'DBAA', 'DGS10', 'DTB3', 'WILL5000IND', # daily\n",
    "]\n",
    "api = '373b8581900f3b2c94da355762d31d7f',\n",
    "start_date = '1960-01-01',\n",
    "end_date = '2021-03-01',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, pathlib, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime\n",
    "\n",
    "params = {\n",
    "    'api_key': api,\n",
    "    'file_type': 'json',\n",
    "    'observation_start': start_date, # date of interest\n",
    "    'realtime_start': start_date, # start of a period (publication date)\n",
    "    'realtime_end': end_date, # end of a period (one day before the next publication date)\n",
    "    }\n",
    "\n",
    "description_keys = [\n",
    "    'id', \n",
    "    'title', \n",
    "    'frequency', \n",
    "    'frequency_short', \n",
    "    'units',\n",
    "    'units_short',\n",
    "    'seasonal_adjustment',\n",
    "    'seasonal_adjustment_short',\n",
    "    'notes',\n",
    "    'observation_start',\n",
    "    'observation_end',\n",
    "]\n",
    "\n",
    "timeout = 10\n",
    "\n",
    "def download_page(url, params):\n",
    "    '''Download page from ALFRED and check whether the download succeeds'''\n",
    "    page = requests.get(url, params=params, timeout=timeout)\n",
    "    if page.status_code == 429:\n",
    "        time.sleep(20)\n",
    "        page = requests.get(url, params=params, timeout=timeout)\n",
    "    assert page.status_code == 200, f\"No {params['series_id']} from {url}, {page.status_code} error\"\n",
    "    return page\n",
    "\n",
    "def float_or_nan(x):\n",
    "    '''Convert a string to either a float number or NaN'''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float('nan')\n",
    "\n",
    "pathData = pathlib.Path('../data')\n",
    "pathAlfred = pathlib.Path( pathData / 'raw' / 'alfred')\n",
    "assert pathData.exists() and pathAlfred.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "for variable in variables:\n",
    "    \n",
    "    params.update({'series_id': variable})\n",
    "    description = dict()\n",
    "\n",
    "    # retrieve the basic description (if exists; if multiple descriptions, retreive the last only)\n",
    "    page = download_page(url='https://api.stlouisfed.org/fred/series', params=params)\n",
    "    page = page.json()['seriess'][-1]\n",
    "    description = {key: page.get(key, '') for key in description_keys}\n",
    "\n",
    "    # retreive the release (if exists)\n",
    "    page = download_page(url='https://api.stlouisfed.org/fred/series/release', params=params)\n",
    "    page = page.json()['releases'][-1]\n",
    "    release_id = page['id']\n",
    "    description['release'] = page.get('name', '')\n",
    "    description['release_url'] = page.get('link', '')\n",
    "    \n",
    "    # retreive the source (if exists)\n",
    "    params_source = params\n",
    "    page = requests.get(\n",
    "        url='https://api.stlouisfed.org/fred/release/sources', \n",
    "        params={'api_key': api, 'file_type': 'json', 'release_id': release_id,}\n",
    "        )\n",
    "    page = page.json()['sources'][-1]\n",
    "    description['source'] = page.get('name', '')\n",
    "    description['source_url'] = page.get('link', '')\n",
    "\n",
    "    # for variables updated in daily frequency, download the last vintage only\n",
    "    if description['frequency_short'] == 'D':\n",
    "        params.update({'realtime_start': end_date})\n",
    "    else:\n",
    "        params.update({'realtime_start': start_date})\n",
    "\n",
    "    # retreive the vintage dates (if available)\n",
    "    page = download_page(url='https://api.stlouisfed.org/fred/series/vintagedates', params=params)\n",
    "    vintage_dates = page.json()['vintage_dates']\n",
    "    description['numberof_vintage_dates'] = len(vintage_dates)\n",
    "    description['is_revised'] = len(vintage_dates) > 1\n",
    "    description['vintage_dates'] = vintage_dates\n",
    "    \n",
    "    descriptions.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data descriptions to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('raw_variables_descriptions.txt', 'w') as json_file:\n",
    "#     json.dump(descriptions, json_file, indent=4)\n",
    "\n",
    "try: \n",
    "\n",
    "    pd_descriptions_old = pd.read_csv(pathData / 'raw_variable_description.csv')\n",
    "    old_variable_set = pd_descriptions_old['id'].to_list()\n",
    "\n",
    "    pd_descriptions_new = pd.DataFrame(descriptions)\n",
    "    new_variable_set = pd_descriptions_new['id'].to_list()\n",
    "\n",
    "    # check whether new variables already exist\n",
    "    duplicated_variables = [variable for variable in new_variable_set if variable in old_variable_set]\n",
    "    if len(duplicated_variables) > 0:\n",
    "        print('\\nWARNING: Some new raw variables already exist and their old information will be removed!\\n')\n",
    "\n",
    "    # drop duplicated variables\n",
    "    pd_descriptions_old.drop(\n",
    "        pd_descriptions_old.index[pd_descriptions_old['id'].map(lambda x: x in duplicated_variables)],\n",
    "        inplace = True\n",
    "        )\n",
    "\n",
    "    # concatenate and save to disk\n",
    "    pd_descriptions = pd.concat([pd_descriptions_old, pd_descriptions_new])\n",
    "    pd_descriptions.to_csv(pathData / 'raw_variable_description.csv', index=False)\n",
    "\n",
    "except:\n",
    "\n",
    "    pd.DataFrame(descriptions).to_csv(pathData / 'raw_variable_description.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and re-organize raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaspe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c426d95761a4b4ea77fd2d54fb966d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d9d30f5427440e8947ea9858735e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f398d81ccdf34aacb52dd3f65122f050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2321a9fc06ae4545ab57a439cf1ba172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variable in variables:\n",
    "\n",
    "    # for variables updated in daily frequency, download the last vintage only\n",
    "    if pd_descriptions[pd_descriptions['id']==variable]['frequency_short'].values[0] == 'D':\n",
    "        params.update({'realtime_start': end_date})\n",
    "    else:\n",
    "        params.update({'realtime_start': start_date})\n",
    "\n",
    "    # download data from ALFRED\n",
    "    params.update({'series_id': variable})\n",
    "    page = download_page(url='https://api.stlouisfed.org/fred/series/observations', params=params)\n",
    "\n",
    "    # convert data type from JSON -> DataFrame\n",
    "    # convert values from string -> float, convert dates from string -> datetime\n",
    "    data = pd.DataFrame(page.json()['observations'])\n",
    "    data['value'] = data['value'].map(lambda x: float_or_nan(x))\n",
    "    for column in data.columns:\n",
    "        if column != 'value':\n",
    "            data[column] = pd.to_datetime(data[column])\n",
    "\n",
    "    # collect all vintage dates\n",
    "    vintage_dates = sorted(list(set(data['realtime_start'].to_list())))\n",
    "\n",
    "    # reshape data structure to ['observation_date', 'VarName_VintDate1', 'VarName_VintDate2', ...]\n",
    "    for index, (observation_date, group) in tqdm_notebook(enumerate(data.groupby('date'))):\n",
    "\n",
    "        if index == 0:\n",
    "\n",
    "            temp_values = {'observation_date': observation_date.strftime('%Y-%m-%d')}\n",
    "\n",
    "            for vintage_date in vintage_dates:\n",
    "                found_value = False\n",
    "                for _, row in group.drop('date', axis=1).iterrows():\n",
    "                    if row['realtime_start'] <= vintage_date <= row['realtime_end']:\n",
    "                        temp_values[f\"{variable}_{vintage_date.strftime('%Y%m%d')}\"] = row['value']\n",
    "                        found_value = True\n",
    "                        break\n",
    "                if found_value == False:\n",
    "                    temp_values[f\"{variable}_{vintage_date.strftime('%Y%m%d')}\"] = float('nan')\n",
    "            assert len(temp_values) == len(vintage_dates) + 1\n",
    "\n",
    "            data_output = pd.DataFrame(temp_values, index=[0])\n",
    "\n",
    "        else:\n",
    "\n",
    "            temp_values = [observation_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "            for vintage_date in vintage_dates:\n",
    "                found_value = False\n",
    "                for _, row in group.drop('date', axis=1).iterrows():\n",
    "                    if row['realtime_start'] <= vintage_date <= row['realtime_end']:\n",
    "                        temp_values.append(row['value'])\n",
    "                        found_value = True\n",
    "                        break\n",
    "                if found_value == False:\n",
    "                    temp_values.append(float('nan'))\n",
    "            assert len(temp_values) == len(vintage_dates) + 1\n",
    "\n",
    "            data_output.loc[data_output.shape[0]] = temp_values\n",
    "\n",
    "    data_output.set_index('observation_date', inplace=True)\n",
    "    data_output.to_csv(pathAlfred / f'{variable}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
