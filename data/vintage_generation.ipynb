{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do\n",
    "# consider the case when there is no vintage date appended to a variable\n",
    "# fill NaN using the values from the last vintage date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_date = '2011-04-01' # until the end of day\n",
    "start_quarter = '1980Q4' # inclusive\n",
    "end_quarter = '2010Q2' # inclusive\n",
    "\n",
    "fillna_from_last_vintage = False\n",
    "variables = {\n",
    "    'raw_variables': set(['GDPC1', ]),\n",
    "    'raw_variables_transform': set([]),\n",
    "    'observed_variables': set([]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('raw_variables')\n",
    "assert data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_date = pd.to_datetime(vintage_date)\n",
    "start_observation = pd.to_datetime(start_quarter).to_period('Q').start_time\n",
    "end_observation = pd.to_datetime(end_quarter).to_period('Q').end_time\n",
    "\n",
    "if vintage_date < end_observation:\n",
    "    warnings.warn('Your vintage date is smaller than the last observation date, so the last observation date will be the vintage date.')\n",
    "    end_observation = vintage_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 90: invalid start byte",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 90: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-24cb917f9858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdescription_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'observed_variable_description.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdescription_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'raw_variable_description.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 90: invalid start byte"
     ]
    }
   ],
   "source": [
    "description_obs = pd.read_excel('observed_variable_description.xlsx')\n",
    "description_raw = pd.read_csv('raw_variable_description.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_obs_raw = dict()\n",
    "\n",
    "if len(variables['observed_variables']) > 0:\n",
    "\n",
    "    # identify corresponding raw variables and store their names in 'raw_variables_tranform'\n",
    "    set_raw_variables = {data_file.stem for data_file in data_path.glob('*.*')}\n",
    "\n",
    "    for _, row in description_obs.iterrows():\n",
    "        if row['id'] in variables['observed_variables']:\n",
    "\n",
    "            set_raw = set()\n",
    "            for raw_variable in set_raw_variables:\n",
    "                if raw_variable in row['construction']:\n",
    "\n",
    "                    set_raw.update({raw_variable})\n",
    "                    variables['raw_variables_transform'].update({raw_variable})\n",
    "            \n",
    "            dict_obs_raw[row['id']] = set_raw\n",
    "\n",
    "    # description_obs = description_obs[description_obs['id'].map(lambda x: x in variables['observed_variables'])]\n",
    "    \n",
    "    # idenfity_string = ' '.join(description_obs['construction'].values)\n",
    "    # for variable in set_raw_variables:\n",
    "    #     if variable in idenfity_string:\n",
    "    #         dict_obs_raw[]\n",
    "    #         variables['raw_variables_transform'].update({variable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raw_variables(variables):\n",
    "\n",
    "    index = -1\n",
    "\n",
    "    for variable in variables:\n",
    "\n",
    "        to_merge = False\n",
    "\n",
    "        for data_file in set(data_path.glob('*.*')):\n",
    "\n",
    "            if data_file.stem == variable:\n",
    "\n",
    "                # load dataset\n",
    "                data_set = pd.read_csv(data_file, index_col=0)\n",
    "                data_set.index = pd.to_datetime(data_set.index)\n",
    "\n",
    "                # load frequency of the variable\n",
    "                frequency = description_raw[description_raw['id']==variable]['frequency_short'].values[0]\n",
    "\n",
    "                # choose data within observation period\n",
    "                observation_dates = data_set.index.map(lambda x: start_observation <= x <= end_observation)\n",
    "\n",
    "                if len(observation_dates.values) == 0:\n",
    "                    warnings.warn(f'\\n{variable} has no value within the observation period you choose for any vintage date!\\n')\n",
    "                    break\n",
    "\n",
    "                # choose data within vintage date\n",
    "                vintage_column = ''\n",
    "\n",
    "                if frequency == 'D':\n",
    "                    vintage_column = data_set.columns.values[-1]\n",
    "                else:\n",
    "                    for column in data_set.columns.values:\n",
    "                        if int(vintage_date.strftime('%Y%m%d')) >= int(column[-8:]):\n",
    "                            vintage_column = column\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                if vintage_column == '':\n",
    "                    warnings.warn(f'\\nFor {variable}, the vintage date you choose is out of bound!\\n')\n",
    "                    break\n",
    "\n",
    "                # combine desired observation period and vintage date\n",
    "                # for daily and monthly data, take the average over the quarter\n",
    "                if len(observation_dates.values) > 0 and vintage_column != '':\n",
    "\n",
    "                    data_set['quarter'] = data_set.index.to_period('Q').values\n",
    "                    data_set = data_set[observation_dates][[vintage_column, 'quarter']].copy()\n",
    "\n",
    "                    if np.sum(~np.isnan(data_set[vintage_column].values)) == 0:\n",
    "                        warnings.warn(f'\\n{variable} has no value in the observation period and vintage date you choose.\\n')\n",
    "                        break\n",
    "                    else:\n",
    "                        index += 1\n",
    "                        to_merge = True\n",
    "                        data_to_merge = data_set.groupby('quarter').mean()\n",
    "\n",
    "                break\n",
    "\n",
    "        if to_merge == True:\n",
    "\n",
    "            if index == 0:\n",
    "                data_output = data_to_merge.copy()\n",
    "            else:\n",
    "                data_output = pd.merge(data_output, data_to_merge, how='outer', left_index=True, right_index=True, sort=True)\n",
    "\n",
    "    return data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data_output' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6926357549dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_raw_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'raw_variables'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_for_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_raw_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'raw_variables_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-82ecd657d47e>\u001b[0m in \u001b[0;36mgenerate_raw_variables\u001b[1;34m(variables)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mdata_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_to_merge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'data_output' referenced before assignment"
     ]
    }
   ],
   "source": [
    "df_raw = generate_raw_variables(variables['raw_variables'])\n",
    "df_for_obs = generate_raw_variables(variables['raw_variables_transform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_for_obs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-56d64ecaa423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdict_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_for_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdict_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_for_obs' is not defined"
     ]
    }
   ],
   "source": [
    "dict_raw = dict()\n",
    "for column in df_for_obs.columns.values:\n",
    "    if column[-8:].isdigit():\n",
    "        dict_raw[column[:-9]] = column\n",
    "    else:\n",
    "        dict_raw[column] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_for_obs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f04681f2561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_for_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_for_obs' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "assert df_raw.shape[0] == df_for_obs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observable in variables['observed_variables']:\n",
    "\n",
    "    vintage_date_observable = 99999999\n",
    "    for raw_variable in dict_obs_raw[observable]:\n",
    "        vintage_date_observable = min(vintage_date_observable, int(dict_raw[raw_variable][-8:]))\n",
    "    column_name = observable + '_' + str(vintage_date_observable)\n",
    "\n",
    "    if observable == 'xgdp_q_obs':\n",
    "        # ΔLN(GDPC1)*100\n",
    "        df.loc[:, column_name] = np.log(df_for_obs[dict_raw['GDPC1']].values/df_for_obs[dict_raw['GDPC1']].shift().values)*100\n",
    "\n",
    "    elif observable == 'pgdp_q_obs':\n",
    "        # ΔLN(GDPCTPI)*100\n",
    "        df.loc[:, column_name] = np.log(df_for_obs[dict_raw['GDPCTPI']].values/df_for_obs[dict_raw['GDPCTPI']].shift().values)*100\n",
    "\n",
    "    elif observable == 'rff_q_obs':\n",
    "        # DFF/4\n",
    "        df.loc[:, column_name] = df_for_obs[dict_raw['DFF']]/4\n",
    "\n",
    "    elif observable == 'fpi_q_obs':\n",
    "        # ΔLN(FPI/GDPCTPI)*100\n",
    "        df.loc[:, column_name] = np.log((df_for_obs[dict_raw['FPI']].values/df_for_obs[dict_raw['GDPCTPI']].values)/(df_for_obs[dict_raw['FPI']].shift().values/df_for_obs[dict_raw['GDPCTPI']].shift().values))*100\n",
    "\n",
    "    elif observable == 'pcer_q_obs':\n",
    "        # ΔLN(PCE/GDPCTPI)*100\n",
    "        df.loc[:, column_name] = np.log((df_for_obs[dict_raw['PCE']].values/df_for_obs[dict_raw['GDPCTPI']].values)/(df_for_obs[dict_raw['PCE']].shift().values/df_for_obs[dict_raw['GDPCTPI']].shift().values))*100\n",
    "\n",
    "    elif observable == 'cp_q_obs':\n",
    "        # (DBAA-DGS10)/4\n",
    "        df.loc[:, column_name] = (df_for_obs[dict_raw['DBAA']] - df_for_obs[dict_raw['DGS10']])/4\n",
    "\n",
    "    elif observable == 'wage_obs':\n",
    "        # ΔLN(COMPNFB/GDPCTPI)*100\n",
    "        df.loc[:, column_name] = np.log((df_for_obs[dict_raw['COMPNFB']].values/df_for_obs[dict_raw['GDPCTPI']].values)/(df_for_obs[dict_raw['COMPNFB']].shift().values/df_for_obs[dict_raw['GDPCTPI']].shift().values))*100\n",
    "\n",
    "    else:\n",
    "        warnings.warn(f'\\n{observable} is not exported as an osbervable.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data_{vintage_date.strftime('%Y%m%d')}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitba3d8e8fc21c4b4c8d5f629dcc40dfe0",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}